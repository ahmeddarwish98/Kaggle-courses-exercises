{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/select-from-where).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nTry writing some **SELECT** statements of your own to explore a large dataset of air pollution measurements.\n\nRun the cell below to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex2 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:09:09.291718Z","iopub.execute_input":"2022-03-16T15:09:09.292023Z","iopub.status.idle":"2022-03-16T15:09:09.298954Z","shell.execute_reply.started":"2022-03-16T15:09:09.291993Z","shell.execute_reply":"2022-03-16T15:09:09.297751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code cell below fetches the `global_air_quality` table from the `openaq` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"openaq\" dataset\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"global_air_quality\" table\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"global_air_quality\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:09:09.30551Z","iopub.execute_input":"2022-03-16T15:09:09.306189Z","iopub.status.idle":"2022-03-16T15:09:10.037739Z","shell.execute_reply.started":"2022-03-16T15:09:09.306137Z","shell.execute_reply":"2022-03-16T15:09:10.036778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Units of measurement\n\nWhich countries have reported pollution levels in units of \"ppm\"?  In the code cell below, set `first_query` to an SQL query that pulls the appropriate entries from the `country` column.\n\nIn case it's useful to see an example query, here's some code from the tutorial:\n\n```\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select countries with units of \"ppm\"\nfirst_query  = \"\"\"\n              SELECT country\n              FROM `bigquery-public-data.openaq.global_air_quality`\n              WHERE unit = \"ppm\"\n              \"\"\"\n# Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nfirst_query_job = client.query(first_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nfirst_results = first_query_job.to_dataframe()\n\n# View top few rows of results\nprint(first_results.head())\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:09:10.039902Z","iopub.execute_input":"2022-03-16T15:09:10.040233Z","iopub.status.idle":"2022-03-16T15:09:10.829299Z","shell.execute_reply.started":"2022-03-16T15:09:10.040191Z","shell.execute_reply":"2022-03-16T15:09:10.82845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_1.solution()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:09:10.830394Z","iopub.execute_input":"2022-03-16T15:09:10.830632Z","iopub.status.idle":"2022-03-16T15:09:10.834986Z","shell.execute_reply.started":"2022-03-16T15:09:10.8306Z","shell.execute_reply":"2022-03-16T15:09:10.834062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) High air quality\n\nWhich pollution levels were reported to be exactly 0?  \n- Set `zero_pollution_query` to select **all columns** of the rows where the `value` column is 0.\n- Set `zero_pollution_results` to a pandas DataFrame containing the query results.","metadata":{}},{"cell_type":"code","source":"# Query to select all columns where pollution levels are exactly 0\nzero_pollution_query = \"\"\"\n                       SELECT *\n                       FROM `bigquery-public-data.openaq.global_air_quality`\n                       WHERE value = 0\n                       \"\"\"\n# Your code goes here\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(zero_pollution_query, job_config=safe_config)\n\n# API request - run the query and return a pandas DataFrame\nzero_pollution_results = query_job.to_dataframe() # Your code goes here\n\nprint(zero_pollution_results.head())\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:09:10.836572Z","iopub.execute_input":"2022-03-16T15:09:10.837387Z","iopub.status.idle":"2022-03-16T15:09:11.723503Z","shell.execute_reply.started":"2022-03-16T15:09:10.83735Z","shell.execute_reply":"2022-03-16T15:09:11.72246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:09:11.725451Z","iopub.execute_input":"2022-03-16T15:09:11.725779Z","iopub.status.idle":"2022-03-16T15:09:11.733709Z","shell.execute_reply.started":"2022-03-16T15:09:11.725738Z","shell.execute_reply":"2022-03-16T15:09:11.732462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That query wasn't too complicated, and it got the data you want. But these **SELECT** queries don't organizing data in a way that answers the most interesting questions. For that, we'll need the **GROUP BY** command. \n\nIf you know how to use [`groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) in pandas, this is similar. But BigQuery works quickly with far larger datasets.\n\nFortunately, that's next.","metadata":{}},{"cell_type":"markdown","source":"# Keep going\n**[GROUP BY](https://www.kaggle.com/dansbecker/group-by-having-count)** clauses and their extensions give you the power to pull interesting statistics out of data, rather than receiving it in just its raw format.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}